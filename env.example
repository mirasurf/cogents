# Cogents Environment Variables Configuration
# Copy this file to .env and fill in your actual values
# 
# NOTE: This file only contains environment variables used in production code.
# Example and test-specific variables are not included.

# =============================================================================
# CORE CONFIGURATION
# =============================================================================

# Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# =============================================================================
# LLM PROVIDER CONFIGURATION
# =============================================================================

# Default LLM provider (openai, anthropic, litellm, ollama, llamacpp, openrouter)
COGENTS_LLM_PROVIDER=openai

# =============================================================================
# OPENAI CONFIGURATION
# =============================================================================

# OpenAI API key (required for OpenAI provider)
OPENAI_API_KEY=your_openai_api_key_here

# OpenAI base URL (default: https://api.openai.com/v1)
OPENAI_BASE_URL=https://api.openai.com/v1

# OpenAI chat model (default: gpt-3.5-turbo)
OPENAI_CHAT_MODEL=gpt-3.5-turbo

# OpenAI vision model (default: gpt-4-vision-preview)
OPENAI_VISION_MODEL=gpt-4-vision-preview

# OpenAI embedding model (default: text-embedding-3-small)
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# =============================================================================
# LITELLM CONFIGURATION
# =============================================================================

# LiteLLM chat model (default: gpt-3.5-turbo)
LITELLM_CHAT_MODEL=gpt-3.5-turbo

# LiteLLM vision model (default: gpt-4-vision-preview)
LITELLM_VISION_MODEL=gpt-4-vision-preview

# LiteLLM embedding model (default: text-embedding-ada-002)
LITELLM_EMBEDDING_MODEL=text-embedding-ada-002

# =============================================================================
# OLLAMA CONFIGURATION
# =============================================================================

# Ollama server base URL (default: http://localhost:11434)
OLLAMA_BASE_URL=http://localhost:11434

# Ollama chat model (default: gemma3:4b)
OLLAMA_CHAT_MODEL=gemma3:4b

# Ollama vision model (default: gemma3:4b)
OLLAMA_VISION_MODEL=gemma3:4b

# Ollama embedding model (default: nomic-embed-text:latest)
OLLAMA_EMBED_MODEL=nomic-embed-text:latest

# =============================================================================
# LLAMACPP CONFIGURATION
# =============================================================================

# LlamaCPP model path (required for LlamaCPP provider)
LLAMACPP_MODEL_PATH=/path/to/your/model.gguf

# LlamaCPP chat model (defaults to model filename)
LLAMACPP_CHAT_MODEL=your_chat_model_name

# LlamaCPP vision model (defaults to model filename)
LLAMACPP_VISION_MODEL=your_vision_model_name

# LlamaCPP embedding model (defaults to model filename)
LLAMACPP_EMBED_MODEL=your_embed_model_name

# =============================================================================
# OPENROUTER CONFIGURATION
# =============================================================================

# OpenRouter API key (required for OpenRouter provider)
OPENROUTER_API_KEY=your_openrouter_api_key_here

# OpenRouter base URL (default: https://openrouter.ai/api/v1)
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

# OpenRouter chat model (default: anthropic/claude-3-haiku)
OPENROUTER_CHAT_MODEL=anthropic/claude-3-haiku

# OpenRouter vision model (default: anthropic/claude-3-haiku)
OPENROUTER_VISION_MODEL=anthropic/claude-3-haiku

# OpenRouter embedding model (default: text-embedding-3-small)
OPENROUTER_EMBED_MODEL=text-embedding-3-small

# =============================================================================
# VECTOR STORE CONFIGURATION
# =============================================================================

# Default vector store provider (weaviate, pgvector)
COGENTS_VECTOR_STORE_PROVIDER=weaviate

# Embedding model dimensions (default: 768)
COGENTS_EMBEDDING_DIMS=768

# =============================================================================
# WEB SEARCH CONFIGURATION
# =============================================================================

# Gemini API key (used by Google AI search)
GEMINI_API_KEY=your_gemini_api_key_here

# =============================================================================
# OPIK TRACING CONFIGURATION
# =============================================================================

# Enable Cogents OPIK tracing (default: false)
COGENTS_OPIK_TRACING=false

# Use local OPIK instance (default: true)
OPIK_USE_LOCAL=true

# OPIK API key (required for remote OPIK)
OPIK_API_KEY=your_opik_api_key_here

# OPIK workspace name
OPIK_WORKSPACE=your_workspace_name

# OPIK project name (default: cogents-llm)
OPIK_PROJECT_NAME=cogents-llm

# Enable OPIK tracing (default: true)
OPIK_TRACING=true

# Local OPIK URL (default: http://localhost:5173)
OPIK_LOCAL_URL=http://localhost:5173

# =============================================================================
# USAGE NOTES
# =============================================================================

# 1. Copy this file to .env in your project root
# 2. Fill in your actual API keys and configuration values
# 3. Never commit .env files to version control
# 4. Use .env.local for local development overrides
# 5. Set required variables for your chosen LLM provider
# 6. Configure vector store settings based on your infrastructure
# 7. Enable OPIK tracing for observability (optional)

# =============================================================================
# REQUIRED VARIABLES BY PROVIDER
# =============================================================================

# OpenAI Provider:
# - OPENAI_API_KEY

# Ollama Provider:
# - No API key required, but ensure Ollama server is running

# LlamaCPP Provider:
# - LLAMACPP_MODEL_PATH

# OpenRouter Provider:
# - OPENROUTER_API_KEY

# Vector Store (Weaviate):
# - WEAVIATE_URL (configured in your application)
# - WEAVIATE_AUTH_SECRET (if authentication enabled)

# Vector Store (PGVector):
# - PGVECTOR_DB, PGVECTOR_USER, PGVECTOR_PASSWORD, PGVECTOR_HOST, PGVECTOR_PORT (configured in your application)
